"""#urlopen (Keep in mind, really urllib.request.urlopen) returns an HTTPResponse object
page = urlopen(test_url)

#Extracting HTML from page by using HTTPResponse object's .read() method
html = page.read().decode("utf-8")

#IMPORTANT!!! Must decode after w/ .decode() ^^Just found out you can do that

#Finally, you can print (Or return if using in a function) the HTML to see contents
#print(html)

#Extracting contents from HTML website
start_index = html.find("<title>")
end_index = html.find("</title>")

title = html[start_index:end_index]

regex.findall("<title>.*</title>", title) #Research more on .search and MatchObject
"""

Beautiful Soup is great for MOST websites. But it sometimes can fail
Does not work with HTML forms :(


Ole reliable is regular expression manipulation

#file1 = open(r"C:\Users\OLAHg\Desktop\web_scraper\stored_image_sources.txt", "w+")




#print(img_getter(souper("https://www.pinterest.com/ideas/wallpapers/951361127909/")))


#image_list = souper.find_all("img")
#print(image_source)

#pattern_1 = "<title.*?>.*?</title.*?"
#search_operand = regex.search(pattern_1, html, regex.IGNORECASE)
#title = search_operand.group()


#ValueError: ~~~ Occurs when there is no https//: and .com extensions in search url
#urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>: ~~~ Occurs when there's no is not a website of this domain


